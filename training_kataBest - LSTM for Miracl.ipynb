{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T02:31:35.711433Z",
     "iopub.status.busy": "2022-12-15T02:31:35.710278Z",
     "iopub.status.idle": "2022-12-15T02:31:35.771395Z",
     "shell.execute_reply": "2022-12-15T02:31:35.770163Z",
     "shell.execute_reply.started": "2022-12-15T02:31:35.711344Z"
    },
    "id": "NVtECQmivObE"
   },
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "#import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from moviepy.editor import *\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T02:31:35.773492Z",
     "iopub.status.busy": "2022-12-15T02:31:35.773122Z",
     "iopub.status.idle": "2022-12-15T02:31:35.909218Z",
     "shell.execute_reply": "2022-12-15T02:31:35.907942Z",
     "shell.execute_reply.started": "2022-12-15T02:31:35.773456Z"
    },
    "id": "kQaMvhOrvObF"
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.keras.utils.set_random_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "execution": {
     "iopub.execute_input": "2022-12-15T02:31:35.927720Z",
     "iopub.status.busy": "2022-12-15T02:31:35.924652Z",
     "iopub.status.idle": "2022-12-15T02:31:36.987205Z",
     "shell.execute_reply": "2022-12-15T02:31:36.986303Z",
     "shell.execute_reply.started": "2022-12-15T02:31:35.927679Z"
    },
    "id": "OvQT7h_qvObG",
    "outputId": "7dc8e13c-24ee-4b2c-89ad-982de0b0c454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10outfinal', '1outfinal', '2outfinal', '3outfinal', '4outfinal', '5outfinal', '6outfinal', '7outfinal', '8outfinal', '9outfinal']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Matplotlib figure and specify the size of the figure.\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "# Get the names of all classes/categories in UCF50.\n",
    "TRAIN_DIR = r'kata/train'\n",
    "VAL_DIR = r'kata/val'\n",
    "TEST_DIR = r'kata/test'\n",
    "all_classes_names = sorted(os.listdir(TRAIN_DIR))\n",
    "print(all_classes_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-15T02:31:36.989789Z",
     "iopub.status.busy": "2022-12-15T02:31:36.988733Z",
     "iopub.status.idle": "2022-12-15T02:31:36.995136Z",
     "shell.execute_reply": "2022-12-15T02:31:36.994097Z",
     "shell.execute_reply.started": "2022-12-15T02:31:36.989750Z"
    },
    "id": "BOxlW0cKvObI"
   },
   "outputs": [],
   "source": [
    "# Specify the height and width to which each video frame will be resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 80, 80\n",
    "\n",
    "# Specify the directory containing the UCF50 dataset. \n",
    "#DATASET_DIR = \"/newdatasetMediapipe/kata/\"\n",
    "\n",
    "# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n",
    "CLASSES_LIST =all_classes_names\n",
    "#CLASSES_LIST = ['2 Tolong', '7 permisi', '1 Maaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-15T02:31:47.262041Z",
     "iopub.status.busy": "2022-12-15T02:31:47.261601Z",
     "iopub.status.idle": "2022-12-15T02:31:47.271196Z",
     "shell.execute_reply": "2022-12-15T02:31:47.270171Z",
     "shell.execute_reply.started": "2022-12-15T02:31:47.262006Z"
    },
    "id": "cm-K7_u7vObJ",
    "outputId": "48634b85-9062-41d5-ec0e-55da6c2c8340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 15#getAverageSequenceLength()\n",
    "print(SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def getDatafromNpz(file):\n",
    "    return file['data'],file['label']\n",
    "dtrain = np.load('feature_train.npz')\n",
    "dval = np.load('feature_val.npz')\n",
    "dtest = np.load('feature_test.npz')\n",
    "\n",
    "features_train,labels_train = getDatafromNpz(dtrain)\n",
    "#cek1 = features_train[0]\n",
    "#features_train, labels_train = shuffle(features_train, labels_train, random_state=0)\n",
    "#cek2 = features_train[0]\n",
    "#if np.array_equal(cek1,cek2):\n",
    "#    print(\"sama\")\n",
    "#else:\n",
    "#    print(\"beda\")\n",
    "\n",
    "\n",
    "features_test,labels_test = getDatafromNpz(dtest)\n",
    "features_val,labels_val = getDatafromNpz(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FXdVjTe0vObQ"
   },
   "outputs": [],
   "source": [
    "#The best\n",
    "def create_convlstm_model():\n",
    "    '''\n",
    "    This function will construct the required LRCN model.\n",
    "    Returns:\n",
    "        model: It is the required constructed LRCN model.\n",
    "    '''\n",
    "\n",
    "    # We will use a Sequential model for model construction.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2)))) \n",
    "    model.add(TimeDistributed(Dropout(0.3)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(\n",
    "        32, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.3)))\n",
    "    \n",
    "    #model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    #model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    #model.add(TimeDistributed(Dropout(0.3)))\n",
    "    \n",
    "    #model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    #model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    #model.add(TimeDistributed(Dropout(0.25)))\n",
    "                                      \n",
    "    model.add(TimeDistributed(Flatten()))#GOAP\n",
    "    #model.add(Dropout(0.4))                               \n",
    "    model.add(LSTM(64, return_sequences=False))#32\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "                                      \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    # Display the models summary.\n",
    "    model.summary()\n",
    "    \n",
    "    # Return the constructed LRCN model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltEwP9GQvObR",
    "outputId": "48e666a7-db70-4e03-bca4-53cf70870acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 15, 80, 80, 16)   448       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 15, 40, 40, 16)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 40, 40, 16)    0         \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 15, 40, 40, 32)   4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 15, 20, 20, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 20, 20, 32)    0         \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 15, 20, 20, 64)   18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 15, 10, 10, 64)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 10, 10, 64)    0         \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 15, 6400)         0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                1655040   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,679,274\n",
      "Trainable params: 1,679,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Construct the required convlstm model.\n",
    "convlstm_model = create_convlstm_model()\n",
    "\n",
    "# Display the success message. \n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AEyh-csyvObR",
    "outputId": "d93c67e4-62e2-45ed-9cf0-03dfed42d1af"
   },
   "outputs": [],
   "source": [
    "# Plot the structure of the contructed model.\n",
    "#plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvulVOJxvObS",
    "outputId": "2f8dd3bb-a5df-43fd-b2b3-5af36cd92700",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "297/297 [==============================] - ETA: 0s - loss: 2.2642 - accuracy: 0.1450\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22667, saving model to MyNet.h5\n",
      "297/297 [==============================] - 8s 12ms/step - loss: 2.2642 - accuracy: 0.1450 - val_loss: 2.1866 - val_accuracy: 0.2267\n",
      "Epoch 2/100\n",
      "296/297 [============================>.] - ETA: 0s - loss: 2.0785 - accuracy: 0.2145\n",
      "Epoch 2: val_accuracy improved from 0.22667 to 0.35333, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 2.0779 - accuracy: 0.2150 - val_loss: 1.8573 - val_accuracy: 0.3533\n",
      "Epoch 3/100\n",
      "294/297 [============================>.] - ETA: 0s - loss: 1.7630 - accuracy: 0.3588\n",
      "Epoch 3: val_accuracy improved from 0.35333 to 0.48000, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 1.7638 - accuracy: 0.3575 - val_loss: 1.5847 - val_accuracy: 0.4800\n",
      "Epoch 4/100\n",
      "291/297 [============================>.] - ETA: 0s - loss: 1.4196 - accuracy: 0.4905\n",
      "Epoch 4: val_accuracy improved from 0.48000 to 0.56000, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 1.4203 - accuracy: 0.4907 - val_loss: 1.3057 - val_accuracy: 0.5600\n",
      "Epoch 5/100\n",
      "292/297 [============================>.] - ETA: 0s - loss: 1.1794 - accuracy: 0.5925\n",
      "Epoch 5: val_accuracy improved from 0.56000 to 0.60667, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 1.1779 - accuracy: 0.5927 - val_loss: 1.1461 - val_accuracy: 0.6067\n",
      "Epoch 6/100\n",
      "292/297 [============================>.] - ETA: 0s - loss: 0.9873 - accuracy: 0.6558\n",
      "Epoch 6: val_accuracy improved from 0.60667 to 0.63333, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.9830 - accuracy: 0.6568 - val_loss: 0.9389 - val_accuracy: 0.6333\n",
      "Epoch 7/100\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.7753 - accuracy: 0.7466\n",
      "Epoch 7: val_accuracy improved from 0.63333 to 0.73333, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.7742 - accuracy: 0.7462 - val_loss: 0.8032 - val_accuracy: 0.7333\n",
      "Epoch 8/100\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.6568 - accuracy: 0.7858\n",
      "Epoch 8: val_accuracy did not improve from 0.73333\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.6567 - accuracy: 0.7867 - val_loss: 0.8994 - val_accuracy: 0.6400\n",
      "Epoch 9/100\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.8387\n",
      "Epoch 9: val_accuracy improved from 0.73333 to 0.78000, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.5172 - accuracy: 0.8373 - val_loss: 0.6323 - val_accuracy: 0.7800\n",
      "Epoch 10/100\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.4395 - accuracy: 0.8486\n",
      "Epoch 10: val_accuracy did not improve from 0.78000\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.4451 - accuracy: 0.8482 - val_loss: 0.7931 - val_accuracy: 0.7267\n",
      "Epoch 11/100\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8788\n",
      "Epoch 11: val_accuracy did not improve from 0.78000\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.3777 - accuracy: 0.8803 - val_loss: 0.6209 - val_accuracy: 0.7800\n",
      "Epoch 12/100\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.3175 - accuracy: 0.9051\n",
      "Epoch 12: val_accuracy improved from 0.78000 to 0.83333, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.3162 - accuracy: 0.9056 - val_loss: 0.4606 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.2348 - accuracy: 0.9260\n",
      "Epoch 13: val_accuracy did not improve from 0.83333\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.2337 - accuracy: 0.9266 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.1842 - accuracy: 0.9517\n",
      "Epoch 14: val_accuracy improved from 0.83333 to 0.85333, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.1834 - accuracy: 0.9519 - val_loss: 0.4276 - val_accuracy: 0.8533\n",
      "Epoch 15/100\n",
      "295/297 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9314\n",
      "Epoch 15: val_accuracy improved from 0.85333 to 0.86667, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.2074 - accuracy: 0.9309 - val_loss: 0.4251 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.9426\n",
      "Epoch 16: val_accuracy did not improve from 0.86667\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.1806 - accuracy: 0.9427 - val_loss: 0.3926 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9662\n",
      "Epoch 17: val_accuracy did not improve from 0.86667\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.1302 - accuracy: 0.9663 - val_loss: 0.4410 - val_accuracy: 0.8267\n",
      "Epoch 18/100\n",
      "293/297 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9753\n",
      "Epoch 18: val_accuracy improved from 0.86667 to 0.88000, saving model to MyNet.h5\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.0873 - accuracy: 0.9739 - val_loss: 0.3246 - val_accuracy: 0.8800\n",
      "Epoch 19/100\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9696\n",
      "Epoch 19: val_accuracy did not improve from 0.88000\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.1169 - accuracy: 0.9696 - val_loss: 0.5835 - val_accuracy: 0.7867\n",
      "Epoch 20/100\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9536\n",
      "Epoch 20: val_accuracy did not improve from 0.88000\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.1447 - accuracy: 0.9536 - val_loss: 0.3939 - val_accuracy: 0.8600\n",
      "Epoch 21/100\n",
      "294/297 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.9668\n",
      "Epoch 21: val_accuracy did not improve from 0.88000\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.1168 - accuracy: 0.9671 - val_loss: 0.5303 - val_accuracy: 0.8067\n",
      "Epoch 22/100\n",
      "296/297 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9738\n",
      "Epoch 22: val_accuracy did not improve from 0.88000\n",
      "297/297 [==============================] - 3s 10ms/step - loss: 0.0885 - accuracy: 0.9739 - val_loss: 0.4092 - val_accuracy: 0.8733\n",
      "Epoch 23/100\n",
      "  8/297 [..............................] - ETA: 2s - loss: 0.0232 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m convlstm_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39madam, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#tf.keras.optimizers.Adam(lr=0.0005)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Start training the model.\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m convlstm_model_training_history \u001b[38;5;241m=\u001b[39m \u001b[43mconvlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeatures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m                                                      \u001b[38;5;66;03m#callbacks = [TerminateOnBaseline(monitor='val_accuracy', baseline=0.96)])\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py:1569\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1567\u001b[0m \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m-> 1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m \u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_increment\u001b[49m\n\u001b[0;32m   1570\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\data_adapter.py:1394\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steps_remaining\n\u001b[0;32m   1392\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1394\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_increment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "cb = TimingCallback()\n",
    "\n",
    "model_ckpt = ModelCheckpoint('MyNet.h5',monitor='val_accuracy', verbose=1,save_best_only=True )\n",
    "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
    "adam=tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "convlstm_model.compile(loss = 'categorical_crossentropy',optimizer=adam, metrics = [\"accuracy\"])\n",
    "#tf.keras.optimizers.Adam(lr=0.0005)\n",
    "# Start training the model.\n",
    "convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 100, batch_size = 4, validation_data=(features_val, labels_val),\n",
    "                                                     callbacks = [cb,model_ckpt])\n",
    "                                                     #callbacks = [TerminateOnBaseline(monitor='val_accuracy', baseline=0.96)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCO_BvfKvObS",
    "outputId": "ed631a9c-3837-4e6f-f62b-af30671bc9dd"
   },
   "outputs": [],
   "source": [
    "print(cb.logs)\n",
    "print(sum(cb.logs))\n",
    "np.save('my_history.npy',convlstm_model_training_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.load('my_history.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm_model_training_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2dUS7jKvObT"
   },
   "outputs": [],
   "source": [
    "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
    "    '''\n",
    "    This function will plot the metrics passed to it in a graph.\n",
    "    Args:\n",
    "        model_training_history: A history object containing a record of training and validation \n",
    "                                loss values and metrics values at successive epochs\n",
    "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
    "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
    "        plot_name:              The title of the graph.\n",
    "    '''\n",
    "    \n",
    "    # Get metric values using metric names as identifiers.\n",
    "    metric_value_1 = model_training_history[metric_name_1]\n",
    "    metric_value_2 = model_training_history[metric_name_2]\n",
    "    \n",
    "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
    "    epochs = range(len(metric_value_1))\n",
    "\n",
    "    # Plot the Graph.\n",
    "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "    # Add title to the plot.\n",
    "    plt.title(str(plot_name))\n",
    "\n",
    "    # Add legend to the plot.\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"output\"+metric_name_1+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ehmlRBMTvObU",
    "outputId": "020a0203-0c43-4259-eade-2112c546598a"
   },
   "outputs": [],
   "source": [
    "# Visualize the training and validation loss metrices.\n",
    "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "zeIlmA3JvObU",
    "outputId": "cdfb9923-9877-434a-89ad-f99545444c48"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the training and validation accuracy metrices.\n",
    "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model.\n",
    "from keras.models import load_model\n",
    "convlstm_model = load_model(\"MyNet.h5\")\n",
    "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loss and accuracy from model_evaluation_history.\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "\n",
    "# Define the string date format.\n",
    "# Get the current Date and Time in a DateTime Object.\n",
    "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "\n",
    "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
    "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Save your Model.\n",
    "convlstm_model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bvV84cbvObV",
    "outputId": "104dc244-6c14-455c-ea80-80d6d51672f9"
   },
   "outputs": [],
   "source": [
    "predict_x=convlstm_model.predict(features_test) \n",
    "rounded_predictions=np.argmax(predict_x,axis=1)\n",
    "\n",
    "print(rounded_predictions[1])\n",
    "\n",
    "rounded_labels=np.argmax(labels_test, axis=1)\n",
    "print(rounded_labels[1])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(rounded_labels, rounded_predictions)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkdqBgJZvObV",
    "outputId": "c44eecc7-8b78-4c92-a6d8-e1bd4bd6d361",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# predict \n",
    "predictions = convlstm_model.predict(features_test)#, batch_size = 4)\n",
    "pred = np.argmax(predictions, axis=1)\n",
    "# label\n",
    "rounded_labels=np.argmax(labels_test, axis=1)\n",
    "\n",
    "print(classification_report(rounded_labels, pred))\n",
    "# precission “Berapa persen mahasiswa yang benar DO dari keseluruhan mahasiswa yang diprediksi DO?”\n",
    "# recall \"Berapa persen mahasiswa yang diprediksi DO dibandingkan keseluruhan mahasiswa yang sebenarnya DO?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff-_bb7TvObW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s49P0UjVvObX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3cbsrQnvObX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
